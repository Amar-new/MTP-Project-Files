{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:07.805404Z","iopub.status.busy":"2024-05-08T07:12:07.804536Z","iopub.status.idle":"2024-05-08T07:12:19.853416Z","shell.execute_reply":"2024-05-08T07:12:19.852276Z","shell.execute_reply.started":"2024-05-08T07:12:07.805361Z"},"id":"IEnlUbgm8z3B","outputId":"b17b53d9-e3c2-4176-e035-a36ca0f3e444","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","import torch\n","import torch.nn as nn\n","import nltk\n","import spacy\n","import re\n","import os\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizerFast, BertConfig,BertModel\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","# download necessary resources\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Set TOKENIZERS_PARALLELISM to false\n","os.environ['TOKENIZERS_PARALLELISM'] = 'false'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:19.856350Z","iopub.status.busy":"2024-05-08T07:12:19.855704Z","iopub.status.idle":"2024-05-08T07:12:19.862179Z","shell.execute_reply":"2024-05-08T07:12:19.860303Z","shell.execute_reply.started":"2024-05-08T07:12:19.856314Z"},"id":"Sm1krxJtKxpx","outputId":"b58db040-78a0-411e-f15e-3f8331afea45","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"5qlmj_T5OskX"},"source":["# Preprocess And Tokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:19.863671Z","iopub.status.busy":"2024-05-08T07:12:19.863354Z","iopub.status.idle":"2024-05-08T07:12:19.943446Z","shell.execute_reply":"2024-05-08T07:12:19.942469Z","shell.execute_reply.started":"2024-05-08T07:12:19.863643Z"},"id":"KLeHl4fSC-Z3","outputId":"148d7f4c-92ad-442b-f99c-78609d7572df","trusted":true},"outputs":[{"data":{"text/plain":["(10000, 5)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# data = pd.read_csv(\"/kaggle/input/10kdataset-corrected/10krowsAttribute_corrected.csv\")\n","data = pd.read_csv(\"/kaggle/input/10kdataset-corrected/10krowsAttributeMissing_words.csv\")\n","\n","data.head()\n","data.shape"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:19.945939Z","iopub.status.busy":"2024-05-08T07:12:19.945624Z","iopub.status.idle":"2024-05-08T07:12:19.956801Z","shell.execute_reply":"2024-05-08T07:12:19.955695Z","shell.execute_reply.started":"2024-05-08T07:12:19.945915Z"},"id":"U8aJw_FWm4Lk","trusted":true},"outputs":[],"source":["# String to add\n","string_to_add = \" <EOS>\"\n","\n","# Add the string to each element in 'col1' using concatenation\n","data['rule_attribute'] = data['rule_attribute'] + string_to_add"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:19.958648Z","iopub.status.busy":"2024-05-08T07:12:19.958315Z","iopub.status.idle":"2024-05-08T07:12:19.971333Z","shell.execute_reply":"2024-05-08T07:12:19.970434Z","shell.execute_reply.started":"2024-05-08T07:12:19.958619Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['sentence', 'word_labels', 'rule_attribute', 'missing_words',\n","       'attr_words'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.columns"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2024-05-08T07:12:19.973496Z","iopub.status.busy":"2024-05-08T07:12:19.972618Z","iopub.status.idle":"2024-05-08T07:12:20.011458Z","shell.execute_reply":"2024-05-08T07:12:20.010495Z","shell.execute_reply.started":"2024-05-08T07:12:19.973465Z"},"id":"SrEgd4PZUgmF","outputId":"e8e24cfc-3412-4d52-8795-399cb9203c96","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","      <th>rule_attribute</th>\n","      <th>missing_words</th>\n","      <th>attr_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The Senate granted Bibulus a thanksgiving of t...</td>\n","      <td>B-ent,I-ent,O,O,O,B-attr,O,B-qty,I-qty</td>\n","      <td>duration thanksgiving &lt;EOS&gt;</td>\n","      <td>duration &lt;EOS&gt;</td>\n","      <td>['thanksgiving']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Takshang is 30.7 km from Gangtok and the popul...</td>\n","      <td>B-ent,O,B-qty,I-qty,B-attr,I-attr,O,O,O,O,O,O,...</td>\n","      <td>distance from Gangtok &lt;EOS&gt;</td>\n","      <td>distance &lt;EOS&gt;</td>\n","      <td>['from', 'Gangtok']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The rocky banks of the Nugush and Belaya rives...</td>\n","      <td>O,B-attr,I-attr,O,B-ent,I-ent,I-ent,I-ent,O,B-...</td>\n","      <td>rocky banks height &lt;EOS&gt;</td>\n","      <td>&lt;EOS&gt;</td>\n","      <td>['rocky', 'banks', 'reach', 'height']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The Padayani was presented for 8 days from Med...</td>\n","      <td>O,B-ent,O,B-attr,O,B-qty,I-qty,O,O,O,O,O</td>\n","      <td>duration presented &lt;EOS&gt;</td>\n","      <td>duration &lt;EOS&gt;</td>\n","      <td>['presented']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Average rainfall in Windsor Locks is 46.27 inches</td>\n","      <td>O,B-attr,O,B-ent,I-ent,O,B-qty,I-qty</td>\n","      <td>average rainfall &lt;EOS&gt;</td>\n","      <td>average &lt;EOS&gt;</td>\n","      <td>['rainfall']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  \\\n","0  The Senate granted Bibulus a thanksgiving of t...   \n","1  Takshang is 30.7 km from Gangtok and the popul...   \n","2  The rocky banks of the Nugush and Belaya rives...   \n","3  The Padayani was presented for 8 days from Med...   \n","4  Average rainfall in Windsor Locks is 46.27 inches   \n","\n","                                         word_labels  \\\n","0             B-ent,I-ent,O,O,O,B-attr,O,B-qty,I-qty   \n","1  B-ent,O,B-qty,I-qty,B-attr,I-attr,O,O,O,O,O,O,...   \n","2  O,B-attr,I-attr,O,B-ent,I-ent,I-ent,I-ent,O,B-...   \n","3           O,B-ent,O,B-attr,O,B-qty,I-qty,O,O,O,O,O   \n","4               O,B-attr,O,B-ent,I-ent,O,B-qty,I-qty   \n","\n","                rule_attribute   missing_words  \\\n","0  duration thanksgiving <EOS>  duration <EOS>   \n","1  distance from Gangtok <EOS>  distance <EOS>   \n","2     rocky banks height <EOS>           <EOS>   \n","3     duration presented <EOS>  duration <EOS>   \n","4       average rainfall <EOS>   average <EOS>   \n","\n","                              attr_words  \n","0                       ['thanksgiving']  \n","1                    ['from', 'Gangtok']  \n","2  ['rocky', 'banks', 'reach', 'height']  \n","3                          ['presented']  \n","4                           ['rainfall']  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_ = data[['sentence', 'word_labels', 'rule_attribute', 'missing_words','attr_words']].drop_duplicates().reset_index(drop=True)\n","df_.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:20.013649Z","iopub.status.busy":"2024-05-08T07:12:20.012930Z","iopub.status.idle":"2024-05-08T07:12:20.021425Z","shell.execute_reply":"2024-05-08T07:12:20.020452Z","shell.execute_reply.started":"2024-05-08T07:12:20.013612Z"},"id":"7MBqY5HmEEMu","outputId":"c7306e10-2d35-4fc3-faf2-1c83aa122468","trusted":true},"outputs":[{"data":{"text/plain":["Index(['sentence', 'word_labels', 'rule_attribute', 'missing_words',\n","       'attr_words'],\n","      dtype='object')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_.columns=['sentence','word_labels','rule_attribute','missing_words','attr_words']\n","df_.columns"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:20.023388Z","iopub.status.busy":"2024-05-08T07:12:20.022838Z","iopub.status.idle":"2024-05-08T07:12:20.032738Z","shell.execute_reply":"2024-05-08T07:12:20.031730Z","shell.execute_reply.started":"2024-05-08T07:12:20.023356Z"},"id":"CFRDM8WsQXvL","outputId":"52a3c0fb-5e26-46e5-8383-47d28939d5f9","trusted":true},"outputs":[{"data":{"text/plain":["{'O': 0,\n"," 'B-ent': 1,\n"," 'I-ent': 2,\n"," 'B-attr': 3,\n"," 'I-attr': 4,\n"," 'B-qty': 5,\n"," 'I-qty': 6}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["Tag = ['O','B-ent','I-ent','B-attr','I-attr','B-qty','I-qty']\n","labels_to_ids = {k: v for v, k in enumerate(Tag)}\n","ids_to_labels = {v: k for v, k in enumerate(Tag)}\n","labels_to_ids"]},{"cell_type":"markdown","metadata":{"id":"f5EHpuB78pIa"},"source":["#### **Preparing the dataset and dataloader**"]},{"cell_type":"markdown","metadata":{"id":"15x7zmZnTgFx"},"source":["Now that our data is preprocessed, we can turn it into PyTorch tensors such that we can provide it to the model. Let's start by defining some key variables that will be used later on in the training/evaluation process:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180,"referenced_widgets":["8ccfb776d3d94d089a0687d5ca5d2e85","57a55c057da247d68e9db6d97c9ae157","b59440f3cec941948fd218eafd64e72e","6719a85f57f14ffa9c0a006394f09b17","b9d8372c69e545f39b9836fea0f2c8b3","65238eee1b9844f39961c64c755767c6","e0f93c3515da4d1f8ff1d9418815a0a0","51a6931ae72b44afa71e77ae07eef6f0","1898071f6a764407979bf2d85566e9c2","85d677c28aaa4500a65fb033b303fb12","48cfb7c25a0342968b7c51dd1d14e7c1","833b5583b33f440aa27779ce30195ddf","925dfdc0e25d4608b291c8159c03a8a3","f5d110799157429790268b727255e735","4e965406e1da41a5a0d0f1b0b6519cb6","e8514f4a8a9b4c18bb18ab857bce13d8","6533149a227b4b989db044831011c9c9","2ced4137480b4975b6eca94b7e5942cf","9bb8242ab34243c98d9bf2fbf75d5401","dca00133749140a9b3fabe0ff34e97ec","298a79fd205a43a984ce387030ac4c4f","2e75474880594d92a0b1b99644699bb3","3d94b0de433245efb0efe916cc99b2e7","3b7895ad6a4143e99bfa5656ce70f197","70d32eeff70542aeaa8852bca89dc03c","969bb478577b454da471721ac4842f95","703dfae603e746e1819e5f114ce772b7","8f455c744b0d40b08820b7a014cca0d6","f2f4c6d997cb4bb884c9ef4ce4b222b0","eb5a25c527604cf0964eeb61546b7304","be629a950be34623a06c48d2ae4909de","e736364f329a42cba503eb778dfe3e3d","10f46cdb1f094dfaabf0c77bac8fbf38","2546eedd8de44153b98cca98420ea7dc","b28a4df322c445cbb24e312f7857bd10","6ff9414071884dbba8bc1b2f8cb55961","8a91eda0605c4431974f87ad9b4accd6","e3d2263a1f5e47ad8b5aa8be7afa8962","2f99cd09e3644a29aadff38fb83bd323","5e734d58d4e542f98ddd63e50579efd8","2c16ff464ae14c029c4b8d15e39f6b4f","2ed2c4ff57af4c33bed4dc4ba15180af","de4e6176b59e4709a9b270a7369cd101","7f046a6ab33d42359c6c7799a7b5ac4f"]},"execution":{"iopub.execute_input":"2024-05-08T07:12:20.034945Z","iopub.status.busy":"2024-05-08T07:12:20.034309Z","iopub.status.idle":"2024-05-08T07:12:21.818911Z","shell.execute_reply":"2024-05-08T07:12:21.818015Z","shell.execute_reply.started":"2024-05-08T07:12:20.034828Z"},"id":"lgNSM8Xz79Mg","outputId":"43567d32-b325-4b08-9f10-fb7c2c575dbb","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ebe2bbeae354baab15d313a85bcf96e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"391b1d633b14431ca0911ebdfe80722e","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b7b5f7cdc694ab398fef05e206b6c93","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"186a334aa0cf431d959759adb240bc3b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["We have added 2 tokens\n"]},{"data":{"text/plain":["30524"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# Let's see how to increase the vocabulary of Bert model and tokenizer\n","# tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n","# model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n","\n","num_added_toks = tokenizer.add_tokens([\"<EOS>\",\"<SOS>\"])\n","print(\"We have added\", num_added_toks, \"tokens\")\n","# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n","# model.resize_token_embeddings(len(tokenizer))\n","len(tokenizer)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:21.821670Z","iopub.status.busy":"2024-05-08T07:12:21.821402Z","iopub.status.idle":"2024-05-08T07:12:21.827473Z","shell.execute_reply":"2024-05-08T07:12:21.826603Z","shell.execute_reply.started":"2024-05-08T07:12:21.821647Z"},"id":"J8HLfPiaWZ9R","outputId":"d0222184-223c-4345-eb9a-9dfc7b9ae75e","trusted":true},"outputs":[{"data":{"text/plain":["([30522], [30523])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# convert_tokens_to_ids\n","tokenizer.convert_tokens_to_ids([\"<EOS>\"]),tokenizer.convert_tokens_to_ids([\"<SOS>\"])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:21.828778Z","iopub.status.busy":"2024-05-08T07:12:21.828525Z","iopub.status.idle":"2024-05-08T07:12:21.840270Z","shell.execute_reply":"2024-05-08T07:12:21.839307Z","shell.execute_reply.started":"2024-05-08T07:12:21.828757Z"},"id":"u4X7BXaGX-JC","outputId":"abfa5f15-f2cc-446e-f554-bf06de99116b","trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [101, 1996, 3164, 4822, 1999, 2885, 1998, 2167, 2637, 2024, 3770, 3867, 3079, 2011, 26419, 4213, 1998, 2322, 3867, 3079, 2011, 5292, 5283, 6806, 3527, 1025, 1996, 2028, 1999, 2900, 2003, 3770, 3867, 3079, 2011, 5292, 5283, 6806, 3527, 1998, 2322, 3867, 3079, 2011, 26419, 4213, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["sent=\"The regional offices in Europe and North America are 80 percent owned by TBWA and 20 percent owned by Hakuhodo ; the one in Japan is 80 percent owned by Hakuhodo and 20 percent owned by TBWA\".split()\n","tokenizer(sent,is_split_into_words=True,max_length=64,add_special_tokens=True,truncation=True)"]},{"cell_type":"markdown","metadata":{"id":"Cr08Lx71VBI3"},"source":["# Encoder Decoder"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:21.841917Z","iopub.status.busy":"2024-05-08T07:12:21.841512Z","iopub.status.idle":"2024-05-08T07:12:21.856838Z","shell.execute_reply":"2024-05-08T07:12:21.856005Z","shell.execute_reply.started":"2024-05-08T07:12:21.841886Z"},"id":"6T3roQbYY5Ie","trusted":true},"outputs":[],"source":["################################## ENCODER - DECODER DATA LOADER ######################################\n","\n","class EncoderDecoderDataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len_encoder,max_len_decoder):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len_encoder = max_len_encoder\n","        self.max_len_decoder = max_len_decoder\n","\n","  def __getitem__(self, index):\n","        # step 1: get the sentence and word labels\n","        sentence = self.data.sentence[index].strip().split()\n","        word_labels = self.data.word_labels[index].split(\",\")\n","#         rule_attribute = self.data.rule_attribute[index].strip().split()\n","        rule_attribute = self.data.missing_words[index].strip().split()\n","\n","        # print(sentence)\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                            # is_pretokenized=True,\n","                            is_split_into_words=True,\n","                            return_offsets_mapping=True,\n","                            padding='max_length',\n","                            truncation=True,\n","                            max_length=self.max_len_encoder)\n","\n","        decoding = self.tokenizer(rule_attribute,\n","                            # is_pretokenized=True,\n","                            is_split_into_words=True,\n","                            return_offsets_mapping=True,\n","                            padding='max_length',\n","                            truncation=True,\n","                            max_length=self.max_len_decoder,\n","                            add_special_tokens= False)\n","\n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [labels_to_ids[label] for label in word_labels]\n","\n","        encode_item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","\n","        encoded_labels=[]\n","        label_index = 0\n","#         new=[1:encoding[\"offset_mapping\"]]\n","        for idx,off_map in enumerate(encoding[\"offset_mapping\"]):\n","#             print(off_map)\n","            start, end= off_map\n","            if start == 0 and end == 0:\n","                encoded_labels.append(-100)\n","            elif start==0 and end!=0:\n","                # Otherwise, append the corresponding label to encoded_labels\n","                encoded_labels.append(labels[label_index])\n","#                 print(encoding[\"offset_mapping\"][idx+1][])\n","                if encoding[\"offset_mapping\"][idx+1][0]==0 and encoding[\"offset_mapping\"][idx+1][1]!=0:\n","                    label_index += 1\n","                 # Move to the next label\n","            elif start!=0 and end!=0:\n","                encoded_labels.append(labels[label_index])\n","                if encoding[\"offset_mapping\"][idx+1][0]==0 and encoding[\"offset_mapping\"][idx+1][1]!=0:\n","                    label_index += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        encode_item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        encode_item['labels'] = torch.as_tensor(encoded_labels)\n","        encode_item['qty_pivot'] = torch.logical_or(encode_item['labels']==5,encode_item['labels']==6).int()\n","\n","\n","        decode_item = {key: torch.as_tensor(val) for key, val in decoding.items()}\n","#         decode_item[\"rule\"]=rule_attribute\n","        return (encode_item,decode_item)\n","############################### ENCODER DATA LOADER ####################\n","  def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:21.858255Z","iopub.status.busy":"2024-05-08T07:12:21.857970Z","iopub.status.idle":"2024-05-08T07:12:21.879206Z","shell.execute_reply":"2024-05-08T07:12:21.878301Z","shell.execute_reply.started":"2024-05-08T07:12:21.858232Z"},"id":"C2Z_FXU2xKuY","outputId":"0d4492fd-9e63-4157-e9f4-d37a3d9c18c3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FULL Dataset: (10000, 5)\n","TRAIN Dataset: (9500, 5)\n","TEST Dataset: (500, 5)\n"]}],"source":["train_size = 0.95\n","train_dataset = df_.sample(frac=train_size,random_state=200)\n","test_dataset = df_.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(df_.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = EncoderDecoderDataset(df_, tokenizer, 64,30)\n","testing_set = EncoderDecoderDataset(test_dataset, tokenizer, 64,10)"]},{"cell_type":"markdown","metadata":{"id":"iaM-3maygSSz"},"source":["# BERT CLASSIFIER CREATION"]},{"cell_type":"markdown","metadata":{"id":"iaX6Qn94m4Ln"},"source":["# Inference Function"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:14:35.715701Z","iopub.status.busy":"2024-05-08T07:14:35.715021Z","iopub.status.idle":"2024-05-08T07:14:35.743525Z","shell.execute_reply":"2024-05-08T07:14:35.742447Z","shell.execute_reply.started":"2024-05-08T07:14:35.715667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Unnamed: 0', 'sentence', 'word_labels', 'rule_attribute'], dtype='object')\n"]}],"source":["import torch.nn.functional as F\n","def get_values_before_first_target(tensor, target):\n","    try:\n","        tensor_list = tensor.tolist()  # Convert tensor to list\n","        index_target = tensor_list.index(target)\n","        return tensor_list[:index_target]\n","    except ValueError:\n","        print(\"Target value not found in the tensor.\")\n","        return tensor_list\n","\n","df_test = pd.read_csv(\"/kaggle/input/testdataqtycorrected/100testrowsqty_corrected.csv\")\n","print(df_test.columns)\n","df_test.drop(\"Unnamed: 0\",inplace=True,axis=1)\n","df_test.columns = [\"sentence\",\"word_labels\",\"rule_attribute\"]\n","\n","def get_encoder_preds(offset_map,flattened_tags):\n","\n","    # Convert logits to predictions (based on argmax or thresholding)\n","#     predictions = torch.argmax(logits, dim=-1)\n","    predicted_labels=[]\n","    label_index = 0\n","#         new=[1:encoding[\"offset_mapping\"]]\n","    count=-1\n","    for idx_off,off_map in enumerate(offset_map[0]):\n","        # print(off_map)\n","        start, end= off_map\n","#             print(\"label_index\",label_index,\" \", (start, end))\n","        # If start and end offsets are both zero, append zero to encoded_labels\n","        if start == 0 and end == 0:\n","            # predicted_labels.append(predictions[0][idx].item())\n","            # actual_labels.append(-100)\n","            count+=1\n","        elif start==0 and end!=0:\n","            # Otherwise, append the corresponding label to encoded_labels\n","            predicted_labels.append(ids_to_labels[flattened_tags[idx_off].item()])\n","#             actual_labels.append(ids_to_labels[labels[0][idx_off].item()])\n","\n","            # predicted_labels.append(predictions[0][idx_off].item())\n","            # actual_labels.append(labels[0][idx_off].item())\n","        if count==1:\n","              break\n","#     print(f\"Sentence: {df_test.sentence[idx]}\")\n","#     print(f\"Predicted_labels: {predicted_labels}\")\n","    return predicted_labels\n","\n","#     actual_list.append(actual_labels)\n","#     sentences.append(df_test.sentence[idx])\n","\n","def encoder_inference(sentence,predsLabels):\n","#     predsLabels = df_pred['Predicted Labels'].values\n","#     sentences = df_pred['Sentence'].values\n","#     attribute_list=[]\n","#     for idx in range(len(sentences)):\n","    attr_words=[]\n","    \n","    preds = predsLabels\n","#     print(len(sentence.split()),len(preds))\n","    \n","#     print(f\"Encoder Inference preds: {preds}\")\n","    for idx_word,word in enumerate(sentence.split()):\n","        # print(predsLabels[idx][1:-1].split(\",\"))\n","        # print(word)\n","        value = preds[idx_word]\n","        if value==\"B-attr\" or value==\"I-attr\":\n","            attr_words.append(word)\n","      # print(attr_words)\n","#       attribute_list.append(\" \".join(attr_words))\n","    return \" \".join(attr_words)\n","\n","\n","def inference_function_merge(df_test,max_len_encoder,max_len_decoder):\n","    pred_list,label_list,sent_list,boolean = [],[],[],[]\n","    model.eval()\n","    test_set = Dataset_inference(df_test, tokenizer, max_len_encoder = max_len_encoder, max_len_decoder=max_len_decoder)\n","\n","    test_params = {'batch_size': 1,\n","                        'shuffle': False,\n","                        'num_workers': 1\n","                        }\n","    testing_loader = DataLoader(test_set, **test_params)\n","    labels_list = []\n","    # for sentence,word_labels,rule_attr in zip(data.sentence,data.labels,data.rule_attri):\n","    for idx, batch in enumerate(testing_loader):\n","#         df.iloc[2]['B']\n","        sentence = df_test.iloc[idx]['sentence']\n","#         print(f\"Sentnece: {sentence}\")\n","\n","        encode_ids = batch[0]['input_ids'].to(device, dtype = torch.long)\n","        encode_mask = batch[0]['attention_mask'].to(device, dtype = torch.long)\n","        # print(f\"Mask Size: {mask.size()}\")\n","        labels = batch[0]['labels'].to(device, dtype = torch.long)\n","        qty_pivot = batch[0]['qty_pivot'].to(device, dtype = torch.long)\n","        offset_map = batch[0]['offset_mapping'].to(device, dtype = torch.long)\n","        decode_ids = batch[1]['input_ids'].to(device, dtype = torch.long)\n","        decode_mask = batch[1]['attention_mask'].to(device, dtype = torch.long)\n","\n","\n","        with torch.no_grad():\n","\n","            # outputs = model(input_ids=encode_ids, attention_mask=encode_mask,target_ids= decode_ids,qty_pivot =qty_pivot,labels=labels)\n","            # print(outputs.size())\n","            encoder_outputs,encoder_logits = model.encode(input_ids=encode_ids, attention_mask=encode_mask,qty_pivot=qty_pivot,labels=labels)\n","\n","            ########### NEWLY ADDED STUFFS #####################\n","            # indices_list = find_indices_of_value(encode_ids, value=102)\n","            active_tags = encoder_logits.view(-1, 7)\n","            flattened_tags = torch.argmax(active_tags, axis=1) # shape (batch_size * seq_len,)\n","#             print(f\"tags:{flattened_tags}\")\n","            \n","            predLabels = get_encoder_preds(offset_map,flattened_tags)\n","            enc_attribute = encoder_inference(sentence,predLabels)\n","            \n","            # attr_tags = torch.logical_or(flattened_tags==3,flattened_tags==4).view(-1,input_ids.size()[1]).type(torch.LongTensor).to(device).unsqueeze(2)\n","#             query = create_query(encode_ids,flattened_tags,decode_ids)\n","            # print(f\"Query in Validation: {query}\")\n","\n","            # memory = model.encode(src, src_mask)\n","            ys,preds = (torch.ones(1, 1)*30523).to(device),[]\n","\n","            for i in range(max_len_decoder):\n","\n","                decoded_outputs = model.decode(input_ids=encode_ids,labels=flattened_tags,encoder_outputs=encoder_outputs,encoder_logits=encoder_logits,target_ids=ys) #whole query\n","                # log_softmax(self.proj(x), dim=-1)\n","                prob = model.generate(decoded_outputs)\n","                # print(f\"Prob dim:  {prob.size()}\")\n","\n","                next_word_probs = torch.softmax(prob, dim=-1)\n","#                 next_word_probs = F.log_softmax(prob, dim=-1)\n","\n","                # print(f\"next_word_probs dim:  {next_word_probs.size()}\")\n","\n","                _, next_word_index = torch.max(next_word_probs, dim=-1)\n","                # print(f\"next word index: {next_word_index.size()}\")\n","                if next_word_index[:,i]==30522:\n","                    break\n","                next_word = tokenizer.convert_ids_to_tokens(next_word_index[:,i])\n","\n","                # _, next_word = torch.max(prob, dim=2)\n","                # print(f\"next word: {next_word}\")\n","                # print(f\"next word dim: {next_word.size()}\")\n","\n","                # next_word = tokenizer.convert_ids_to_tokens(next_word)\n","                # print(f\"next word: {next_word}\")\n","                # print(f\"next_word_index.item(): {next_word_index[:,i]}\")\n","\n","                # Convert next_word_index tensor to the device before concatenating\n","                next_word_index_tensor = torch.ones(1, 1, device=device) * next_word_index[:, i]\n","\n","                # Concatenate tensors\n","                preds.append(next_word[0])\n","                ys = torch.cat([ys, next_word_index_tensor], dim=1)\n","            # print(\"Example Untrained Model Prediction:\", ys,preds)\n","            \n","            pred_list.append(\" \".join(preds)+\" \"+enc_attribute)\n","            labels_list.append(predLabels)\n","\n","    return pred_list,labels_list"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:22.620313Z","iopub.status.busy":"2024-05-08T07:12:22.619959Z","iopub.status.idle":"2024-05-08T07:12:22.635102Z","shell.execute_reply":"2024-05-08T07:12:22.634057Z","shell.execute_reply.started":"2024-05-08T07:12:22.620284Z"},"trusted":true},"outputs":[],"source":["################################## ENCODER - DECODER DATA LOADER ######################################\n","\n","class Dataset_inference(Dataset):\n","        def __init__(self, dataframe, tokenizer, max_len_encoder,max_len_decoder):\n","            self.len = len(dataframe)\n","            self.data = dataframe\n","            self.tokenizer = tokenizer\n","            self.max_len_encoder = max_len_encoder\n","            self.max_len_decoder = max_len_decoder\n","\n","        def __getitem__(self, index):\n","            # step 1: get the sentence and word labels\n","            sentence = self.data.sentence[index].strip().split()\n","            word_labels = self.data.word_labels[index].split(\",\")\n","            rule_attribute = self.data.rule_attribute[index].strip().split()\n","    #         rule_attribute = self.data.missing_words[index].strip().split()\n","\n","            # print(sentence)\n","            # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","            # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","            encoding = self.tokenizer(sentence,\n","                                # is_pretokenized=True,\n","                                is_split_into_words=True,\n","                                return_offsets_mapping=True,\n","                                padding='max_length',\n","                                truncation=True,\n","                                max_length=self.max_len_encoder)\n","\n","            decoding = self.tokenizer(rule_attribute,\n","                                # is_pretokenized=True,\n","                                is_split_into_words=True,\n","                                return_offsets_mapping=True,\n","                                padding='max_length',\n","                                truncation=True,\n","                                max_length=self.max_len_decoder,\n","                                add_special_tokens= False)\n","\n","            # step 3: create token labels only for first word pieces of each tokenized word\n","            labels = [labels_to_ids[label] for label in word_labels]\n","\n","            encode_item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","\n","            encoded_labels=[]\n","            label_index = 0\n","    #         new=[1:encoding[\"offset_mapping\"]]\n","            for idx,off_map in enumerate(encoding[\"offset_mapping\"]):\n","    #             print(off_map)\n","                start, end= off_map\n","                if start == 0 and end == 0:\n","                    encoded_labels.append(-100)\n","                elif start==0 and end!=0:\n","                    # Otherwise, append the corresponding label to encoded_labels\n","                    encoded_labels.append(labels[label_index])\n","    #                 print(encoding[\"offset_mapping\"][idx+1][])\n","                    if encoding[\"offset_mapping\"][idx+1][0]==0 and encoding[\"offset_mapping\"][idx+1][1]!=0:\n","                        label_index += 1\n","                     # Move to the next label\n","                elif start!=0 and end!=0:\n","                    encoded_labels.append(labels[label_index])\n","                    if encoding[\"offset_mapping\"][idx+1][0]==0 and encoding[\"offset_mapping\"][idx+1][1]!=0:\n","                        label_index += 1\n","\n","            # step 4: turn everything into PyTorch tensors\n","            encode_item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","            encode_item['labels'] = torch.as_tensor(encoded_labels)\n","            encode_item['qty_pivot'] = torch.logical_or(encode_item['labels']==5,encode_item['labels']==6).int()\n","\n","\n","            decode_item = {key: torch.as_tensor(val) for key, val in decoding.items()}\n","    #         decode_item[\"rule\"]=rule_attribute\n","            return (encode_item,decode_item)\n","        ############################### ENCODER DATA LOADER ####################\n","        def __len__(self):\n","            return self.len"]},{"cell_type":"markdown","metadata":{"id":"vo4wGp5cm4Ln"},"source":["# Utilities"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-08T07:12:48.312438Z","iopub.status.busy":"2024-05-08T07:12:48.311642Z","iopub.status.idle":"2024-05-08T07:12:48.330728Z","shell.execute_reply":"2024-05-08T07:12:48.329838Z","shell.execute_reply.started":"2024-05-08T07:12:48.312394Z"},"id":"dJ6Mfe_Um4Lo","outputId":"e17df23e-6dcb-46e2-e8c0-147c2a94e85b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Unnamed: 0', 'sentence', 'word_labels', 'rule_attribute'], dtype='object')\n"]}],"source":["\n","def preprocess_attr(text):\n","  # lowercase the text\n","    text = str(text).lower().strip()\n","    '''text=text.replace(\"'s\",\"\")text=text.replace(\" 's\",\"\")'''\n","\n","# tokenize the text\n","    tokens = nltk.word_tokenize(text)\n","    for i in range(len(tokens)):\n","        w=tokens[i]\n","\n","        w=w.replace(\" \",\"\")\n","        tokens[i]=w\n","\n","    # remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","  #  print(filtered_tokens)\n","    # remove special characters using regex\n","    preprocessed_text = ' '.join(tokens)\n","    # process the text with spaCy\n","    doc = nlp(preprocessed_text)\n","\n","  # lemmatize each token and join them back into a string\n","    #SpaCy lemmatizer\n","    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n","    text = re.sub('[^a-zA-Z0-9\\s]', '',  lemmatized_text)\n","    #text=re.sub('[^a-zA-Z0-9\\s]', '',  preprocessed_text)\n","    tokens = nltk.word_tokenize(text)\n","    return tokens\n","\n","def relaxed_precision(pred, gt):\n","    # split predicted and ground truth into words\n","    # calculate overlap\n","    overlap = len(set(pred).intersection(set(gt)))\n","\n","    # calculate relaxed precision\n","    if(len(pred)!=0):\n","        rp = overlap / len(pred)\n","    else:\n","        rp=0\n","    return rp\n","\n","def relaxed_recall(pred, gt):\n","    # calculate overlap\n","    overlap = len(set(pred).intersection(set(gt)))\n","\n","    if(len(gt)!=0):\n","    # calculate relaxed recall\n","        rr = overlap / len(gt)\n","    else:\n","        rr=0\n","\n","    return rr\n","\n","\n","df_decoder = pd.read_csv(\"/kaggle/input/testdataqtycorrected/100testrowsqty_corrected.csv\")\n","print(df_decoder.columns)\n","# decoder_attr = df_decoder[\"predictedAttribute\"].values\n","ground_truth_attr = df_decoder[\"rule_attribute\"].values\n","sent = df_decoder[\"sentence\"].values\n","\n","\n","def check_F1_score(ground_truth_attr,decoder_attr):\n","    relaxed_precisions = []\n","    relaxed_recalls = []\n","\n","    for i in range(len(ground_truth_attr)):\n","        rp = relaxed_precision(preprocess_attr(decoder_attr[i]),preprocess_attr(ground_truth_attr[i]))\n","        rr = relaxed_recall(preprocess_attr(decoder_attr[i]),preprocess_attr(ground_truth_attr[i]))\n","        relaxed_precisions.append(rp)\n","        relaxed_recalls.append(rr)\n","\n","    # calculate average relaxed precision and recall\n","    avg_relaxed_precision = np.mean(relaxed_precisions)\n","    avg_relaxed_recall = np.mean(relaxed_recalls)\n","    # print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n","    # print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n","    f1score = (2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)\n","#     print(f\"f1 score for attribute: {f1score}\")\n","    return f1score,decoder_attr"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:48.850042Z","iopub.status.busy":"2024-05-08T07:12:48.849687Z","iopub.status.idle":"2024-05-08T07:12:48.883445Z","shell.execute_reply":"2024-05-08T07:12:48.882384Z","shell.execute_reply.started":"2024-05-08T07:12:48.850014Z"},"id":"nIb3aR0dm4Lo","trusted":true},"outputs":[],"source":["# Defining the training function on the 80% of the dataset for tuning the bert model\n","def train(training_loader,alpha=0.5,MAX_GRAD_NORM=3):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training model\n","    model.train()\n","\n","    for idx, batch in enumerate(training_loader):\n","\n","        encode_ids = batch[0]['input_ids'].to(device, dtype = torch.long)\n","        mask = batch[0]['attention_mask'].to(device, dtype = torch.long)\n","        # print(f\"Mask Size: {mask.size()}\")\n","        qty_pivot = batch[0]['qty_pivot'].to(device, dtype = torch.long)\n","        labels = batch[0]['labels'].to(device, dtype = torch.long)\n","        decode_ids = batch[1]['input_ids'].to(device, dtype = torch.long)\n","        decode_mask = batch[1]['attention_mask'].to(device, dtype = torch.long)\n","\n","\n","        # print(ids.size(),mask.size(),labels.size())\n","        # outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        outputs = model(input_ids=encode_ids, attention_mask=mask,qty_pivot=qty_pivot,labels=labels,target_ids= decode_ids)\n","\n","        decoded_outputs,hidden_states,enc_logits = outputs[0],outputs[1],outputs[2]\n","\n","        logits_decoder = model.generate(decoded_outputs)\n","        # print(f\"Logits decoder: {logits_decoder.size()}\")\n","\n","        logits_flat = logits_decoder[:, 0:].contiguous().view(-1, logits_decoder.size(-1))\n","        decoder_target_ids_flat = decode_ids.contiguous().view(-1)\n","\n","        enc_logits_flat = enc_logits[:,0:].contiguous().view(-1,enc_logits.size(-1))\n","        enc_flat_true =  labels.contiguous().view(-1)\n","        # # Cross-Entropy Loss\n","        # print(f\"Logits Flat Size: {logits_flat}\")\n","        # print(f\"Shifted Input Ids Size: {shifted_input_ids_flat}\")\n","        # print(f\"Shifted Input Ids: {shifted_input_ids_flat}\")\n","        # print(f\"Logits Flat Values: {logits_flat}\")\n","        loss_fn_dec = nn.CrossEntropyLoss(ignore_index=0,label_smoothing=0.1)  # Specify the pad_token_id\n","        loss_fn_enc = nn.CrossEntropyLoss(ignore_index=-100)\n","        initial_loss_enc = loss_fn_enc(enc_logits_flat,enc_flat_true)\n","        initial_loss_dec = loss_fn_dec(logits_flat, decoder_target_ids_flat)\n","        # print(outputs.size())\n","        # initial_loss,tr_logits = outputs[0],outputs[1]\n","\n","        # print(tr_logits.size(),\"Logits Size\")\n","        # print(\"LOss:\",loss, \"Logits:\",tr_logits)\n","\n","        # initial_loss\n","        # print(initial_loss.item(),\"\\n\",logits)\n","#         alpha=0.45\n","        alpha=alpha\n","        total_loss = (1-alpha)*initial_loss_enc+ alpha*initial_loss_dec\n","        tr_loss+= (1-alpha)*initial_loss_enc.item()+ alpha*initial_loss_dec.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","\n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            # print(f\"Training loss per 100 training steps: {loss_step}\")\n","\n","        # compute training accuracy\n","        flattened_targets = decode_ids.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = logits_decoder.view(-1, 30524) # shape (batch_size * seq_len, num_labels)\n","\n","        # print(\"Active logits\",active_logits.shape)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","\n","        # print(\"Flattened predictions\",flattened_predictions)\n","        # print(\"Flattened predictions Shape\",flattened_predictions.size())\n","        # print(\"Flattened Targets\",flattened_targets)\n","        # print(\"Flattened Targets Shape\",flattened_targets.size())\n","\n","        # print(\"Labels\",labels.shape)\n","        # only compute accuracy at active labels\n","        active_accuracy = flattened_targets.view(-1)!=0 # shape (batch_size, seq_len)\n","        # print(active_accuracy,\"Active Accuracy\")\n","        # active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        # print(\"Active accuracy\",active_accuracy)\n","\n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        # print(f\"Active labels: {labels}\")\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        # print(f\"Predicted labels: {predictions}\")\n","\n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","\n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","\n","        # backward pass\n","        optimizer.zero_grad()\n","        total_loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kUMyWuCym4Lo"},"source":["# BERT Classifier"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:50.226963Z","iopub.status.busy":"2024-05-08T07:12:50.226598Z","iopub.status.idle":"2024-05-08T07:12:50.257652Z","shell.execute_reply":"2024-05-08T07:12:50.256603Z","shell.execute_reply.started":"2024-05-08T07:12:50.226932Z"},"id":"qwL2Jo4XJICR","trusted":true},"outputs":[],"source":["from transformers.models.bert.modeling_bert import BertEncoder, BertPooler, BertEmbeddings, BaseModelOutputWithPoolingAndCrossAttentions\n","from transformers import BertConfig, BertModel\n","import torch\n","from torch import nn\n","\n","# https://discuss.huggingface.co/t/how-to-use-additional-input-features-for-ner/4364/26\n","\n","class BertEmbeddingsV2(BertEmbeddings):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n","        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n","        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n","        max_number_of_pos_tags = 2\n","        self.pos_tag_embeddings = nn.Embedding(max_number_of_pos_tags, config.hidden_size)\n","\n","        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n","        # any TensorFlow checkpoint file\n","        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n","        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n","        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n","\n","    def forward(self, input_ids=None, qty_pivot=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0):\n","        if input_ids is not None:\n","            input_shape = input_ids.size()\n","        else:\n","            input_shape = inputs_embeds.size()[:-1]\n","\n","        seq_length = input_shape[1]\n","\n","        if position_ids is None:\n","            position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n","\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n","\n","        if inputs_embeds is None:\n","            inputs_embeds = self.word_embeddings(input_ids)\n","        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n","        # print(f\"Qty Pivot: {qty_pivot}\")\n","        pos_tag_embeddings = self.pos_tag_embeddings(qty_pivot)\n","\n","        embeddings = inputs_embeds + token_type_embeddings + pos_tag_embeddings\n","        if self.position_embedding_type == \"absolute\":\n","            position_embeddings = self.position_embeddings(position_ids)\n","            embeddings += position_embeddings\n","        embeddings = self.LayerNorm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings\n","\n","class BertModelV2(BertModel):\n","    \"\"\"\n","    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n","    cross-attention is added between the self-attention layers, following the architecture described in `Attention is\n","    all you need <https://arxiv.org/abs/1706.03762>`__ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n","    Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n","    To behave as an decoder the model needs to be initialized with the :obj:`is_decoder` argument of the configuration\n","    set to :obj:`True`. To be used in a Seq2Seq model, the model needs to initialized with both :obj:`is_decoder`\n","    argument and :obj:`add_cross_attention` set to :obj:`True`; an :obj:`encoder_hidden_states` is then expected as an\n","    input to the forward pass.\n","    \"\"\"\n","\n","    def __init__(self, config, add_pooling_layer=False):\n","        super().__init__(config)\n","        self.config = config\n","\n","        self.embeddings = BertEmbeddingsV2(config)\n","        self.encoder = BertEncoder(config)\n","\n","        self.pooler = BertPooler(config) if add_pooling_layer else None\n","\n","        self.init_weights()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        # pos_tag_ids=None,\n","        qty_pivot = None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        encoder_hidden_states=None,\n","        encoder_attention_mask=None,\n","        past_key_values=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=True,\n","        return_dict=None,\n","    ):\n","        \"\"\"\n","        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n","            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n","            the model is configured as a decoder.\n","        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n","            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n","            - 1 for tokens that are **not masked**,\n","            - 0 for tokens that are **masked**.\n","        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n","            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n","            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n","            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n","            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n","        use_cache (:obj:`bool`, `optional`):\n","            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n","            decoding (see :obj:`past_key_values`).\n","        \"\"\"\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if self.config.is_decoder:\n","            use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        else:\n","            use_cache = False\n","\n","        if input_ids is not None and inputs_embeds is not None:\n","            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n","        elif input_ids is not None:\n","            input_shape = input_ids.size()\n","            batch_size, seq_length = input_shape\n","        elif inputs_embeds is not None:\n","            input_shape = inputs_embeds.size()[:-1]\n","            batch_size, seq_length = input_shape\n","        else:\n","            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n","\n","        device = input_ids.device if input_ids is not None else inputs_embeds.device\n","\n","        # past_key_values_length\n","        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n","\n","        if attention_mask is None:\n","            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n","\n","        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n","        # ourselves in which case we just need to make it broadcastable to all heads.\n","        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n","\n","        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n","        if self.config.is_decoder and encoder_hidden_states is not None:\n","            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n","            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n","            if encoder_attention_mask is None:\n","                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n","            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n","        else:\n","            encoder_extended_attention_mask = None\n","\n","        # Prepare head mask if needed\n","        # 1.0 in head_mask indicate we keep the head\n","        # attention_probs has shape bsz x n_heads x N x N\n","        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n","        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n","        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n","\n","        # print(f\"Define V2 Qty_pivot: {qty_pivot.size()}\")\n","\n","        embedding_output = self.embeddings(\n","            input_ids=input_ids,\n","            position_ids=position_ids,\n","            token_type_ids=token_type_ids,\n","            # pos_tag_ids=pos_tag_ids,\n","            qty_pivot = qty_pivot,\n","            inputs_embeds=inputs_embeds,\n","            past_key_values_length=past_key_values_length,\n","        )\n","        encoder_outputs = self.encoder(\n","            embedding_output,\n","            attention_mask=extended_attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_extended_attention_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        sequence_output = encoder_outputs[0]\n","        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n","\n","#         print(f\"Encoder first: {encoder_outputs[1:][0][1].size()}\")\n","#         print(f\"Encoder Output : {len(encoder_outputs[1:][0])}\")\n","#         print(f\"Hidden States: {len(encoder_outputs.hidden_states)}\")\n","#         print(f\"Encoder zero: {encoder_outputs[1:][0][0].size()}\")\n","#         print(f\"Hiden State 1st: {encoder_outputs.hidden_states[0][0].size()}\")\n","#         print(f\"Hiden State 2nd: {encoder_outputs.hidden_states[1][0].size()}\")\n","\n","        '''\n","        Encoder first: torch.Size([4, 128, 768])\n","        Encoder Output : 13      ---------- this is what we take forward\n","        Hidden States: 13\n","        Encoder zero: torch.Size([4, 128, 768])\n","        Hiden State 1st: torch.Size([128, 768])\n","        Hiden State 2nd: torch.Size([128, 768])\n","        '''\n","        if not return_dict:\n","            return (sequence_output, pooled_output) + encoder_outputs[1:]\n","\n","        return BaseModelOutputWithPoolingAndCrossAttentions(\n","            last_hidden_state=sequence_output,\n","            pooler_output=pooled_output,\n","            past_key_values=encoder_outputs.past_key_values,\n","            hidden_states=encoder_outputs.hidden_states,\n","            attentions=encoder_outputs.attentions,\n","            cross_attentions=encoder_outputs.cross_attentions,\n","        )\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:50.464997Z","iopub.status.busy":"2024-05-08T07:12:50.464386Z","iopub.status.idle":"2024-05-08T07:12:50.490910Z","shell.execute_reply":"2024-05-08T07:12:50.489800Z","shell.execute_reply.started":"2024-05-08T07:12:50.464955Z"},"id":"UyPW_La5JPfB","trusted":true},"outputs":[],"source":["\n","# Create the BertClassfier class\n","class BertClassifier_1(nn.Module):\n","    \"\"\"\n","    Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, tokenizer, freeze_bert=False,num_labels=len(labels_to_ids),drop1=0.1,drop2=0.1,activation=\"relu\"):\n","\n","        super(BertClassifier_1, self).__init__()\n","\n","        # Instantiate BERT model\n","        # self.embedding_1 =  nn.Embedding(n, d, max_norm=False)\n","        self.num_labels=num_labels\n","        # self.bert = BertModel.from_pretrained('bert-base-uncased',add_pooling_layer=False)\n","        self.activation = activation\n","        config = BertConfig()\n","        self.bertV2 = BertModelV2.from_pretrained(\"bert-base-uncased\", config=config)\n","        self.bertV2.resize_token_embeddings(len(tokenizer))\n","        self.enc_modules = [self.bertV2.embeddings , self.bertV2.encoder.layer[:10]]\n","#         self.enc_modules = [self.bertV2.encoder.layer[:10]]\n","\n","        # D_in, H, D_out = 768, 264, self.num_labels\n","\n","        D_in,H_1,H_2,H_3,D_out = 768, 512,264,128,self.num_labels\n","\n","#         self.fc1 = nn.Dropout(drop1)\n","        self.fc2 = nn.Linear(D_in,H_1)#768x512\n","        self.fc3 = nn.Dropout(drop1)\n","        self.fc4 = nn.Linear(H_1,H_2)#512x264\n","        self.fc5 = nn.Dropout(drop2)\n","        self.fc6 = nn.Linear(H_2,D_out)\n","#         self.fc7 = nn.Linear(H_3,D_out)#128x7\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","        self.gelu = nn.GELU()\n","\n","        # count = 0\n","        # for param in self.bertV2.parameters():\n","        #     count+=1\n","        #     if count<=165:\n","        #       param.requires_grad = False\n","\n","        for module in self.enc_modules:\n","            for param in module.parameters():\n","                param.requires_grad = False\n","\n","#         for name, param in self.bertV2.named_parameters():\n","#           if name==\"embeddings.pos_tag_embeddings.weight\":\n","# #             print(\"Worked\")\n","#             param.requires_grad=True\n","\n","#         for name, param in self.bertV2.named_parameters():\n","# #           if name==\"bertV2.embeddings.pos_tag_embeddings.weight\":\n","#             print(name,param.requires_grad)\n","#         # self.bertV2.embeddings.pos_tag_embeddings.parameters =  True\n","\n","    def forward(self, input_ids, attention_mask,qty_pivot,labels):\n","      ## ADD MASK LABELS as well here, positioning or something,\n","      # def forward(self, encoding):\n","\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","\n","        outputs = self.bertV2(input_ids=input_ids,attention_mask=attention_mask,qty_pivot=qty_pivot)\n","        # print(\"Last Hidden State size: \", outputs['last_hidden_state'].size())\n","        ## find the output where the pivoting for masking is done from the dataset, send that to get the MASK prediction into one of the labels\n","#         self.labels=labels\n","\n","        if self.activation==\"relu\":\n","#             x = self.fc1(outputs.last_hidden_state)\n","            x = self.relu(outputs.last_hidden_state)\n","            x = self.fc2(x)\n","            x = self.relu(x)\n","            x = self.fc3(x)\n","            x = self.fc4(x)\n","            x = self.relu(x)\n","            x = self.fc5(x)\n","\n","            logits = self.fc6(x)\n","\n","\n","\n","        else:\n","            x = self.fc1(outputs.last_hidden_state)\n","            x = self.fc2(x)\n","            x = self.tanh(x)\n","            x = self.fc3(x)\n","            logits = self.fc4(x)\n","\n","\n","        return outputs,logits\n","\n","# model = BertClassifier_1(tokenizer=tokenizer,freeze_bert=True)\n","# model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"eGnMRiKYsQlp"},"source":["# SEQ2SEQ MODEL"]},{"cell_type":"markdown","metadata":{"id":"riNzS1iym4Lv"},"source":["**When it was providing answers it was because the fact that answer was already given to it in the query.** <br>\n","**So we generate the answers from the Tagging thing and feed it to the decoder as QUERY** <br>\n","**Thus helping the model to see what it needs to see. Also, it can be the point that encoder is more weighed upon then the decoder.**"]},{"cell_type":"markdown","metadata":{"id":"_xLg2Vuim4Lv"},"source":["* Few Experiments:\n","1. Use the general one currently trying with only 8 decoder layers.<br> <br>\n","2. Use the one with Query from the Encoder output tags, enforcing the important attributes. <br> Play with the weights of loss.<br>\n","**Remember to put **is_causal=False**<br>\n","3. Train the Encoder alone, see what can be done about it.<br> <br>\n","4. Use the trained encoder to give the decoder the query output which are tagged as attribute. along with CLS and not with CLS."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:12:55.496702Z","iopub.status.busy":"2024-05-08T07:12:55.495998Z","iopub.status.idle":"2024-05-08T07:12:55.503901Z","shell.execute_reply":"2024-05-08T07:12:55.502887Z","shell.execute_reply.started":"2024-05-08T07:12:55.496670Z"},"id":"v1UOO5t8m4Lv","trusted":true},"outputs":[],"source":["# import torch\n","\n","def apply_mask_to_encoder_hidden_state(encoder_hidden_state, attribute_tags, indices):\n","    # Apply the mask\n","    masked_tensor = torch.zeros_like(attribute_tags)\n","    for i, row in enumerate(attribute_tags):\n","        indices_to_mask = indices[i]\n","#         print(f\"row value: {row}\")\n","        masked_tensor[i, :indices_to_mask] = row[:indices_to_mask]\n","\n","    # Expand the dimensions of mask_tensor to match the shape of encoder_hidden_state\n","    expanded_mask = masked_tensor.unsqueeze(-1).expand_as(encoder_hidden_state)\n","\n","    # Apply the mask\n","    masked_encoder_hidden_state = encoder_hidden_state * expanded_mask\n","\n","    return masked_encoder_hidden_state\n","\n","\n","def find_indices_of_value(input_ids, value=102):\n","    indices_list = []\n","    for row in input_ids:\n","        indices = torch.where(row == value)[0]\n","        indices_list.append(indices.item() if len(indices) > 0 else None)\n","#     print(f\"Indices function: {indices_list}\")\n","    return indices_list\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["55f9fc24e0d64491b7fa039fc7aaba5b","088437bf51344b7aadaddbcec77b8277","208de58f057f47c785f9f0cdb9ca06e5","ed35974842614bfc9eec6795f003b5b7","629d6edd90e64690a5f6f17705ad9133","55d197ab664344458470220d26f2183b","5a79dfcad4434bc38e27daf925d920d5","9d334f3291ba4fa592c28eb3b9095e7f","407489118d924fa49d98cfd4596b93ae","2ab95d39f0974e8f9a3099b6c205e33f","3eb13f11069548b9b51c4f170d7a23ba"]},"execution":{"iopub.execute_input":"2024-05-08T07:12:56.882767Z","iopub.status.busy":"2024-05-08T07:12:56.882398Z","iopub.status.idle":"2024-05-08T07:13:01.088786Z","shell.execute_reply":"2024-05-08T07:13:01.087843Z","shell.execute_reply.started":"2024-05-08T07:12:56.882738Z"},"id":"1kEB-1RIMTjD","outputId":"537471c5-27f1-496d-c21c-c082ecf9887b","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35b71802cab8481394d7ecc066d3e394","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertModelV2 were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.pos_tag_embeddings.weight', 'bert.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertSeq2SeqClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30524, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (bert_model): BertClassifier_1(\n","    (bertV2): BertModelV2(\n","      (embeddings): BertEmbeddingsV2(\n","        (word_embeddings): Embedding(30524, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (pos_tag_embeddings): Embedding(2, 768)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): None\n","    )\n","    (fc2): Linear(in_features=768, out_features=512, bias=True)\n","    (fc3): Dropout(p=0.1, inplace=False)\n","    (fc4): Linear(in_features=512, out_features=264, bias=True)\n","    (fc5): Dropout(p=0.1, inplace=False)\n","    (fc6): Linear(in_features=264, out_features=7, bias=True)\n","    (relu): ReLU()\n","    (tanh): Tanh()\n","    (gelu): GELU(approximate='none')\n","  )\n","  (transformer_decoder): TransformerDecoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n","        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","        (dropout3): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (relu): ReLU()\n","  (tanh): Tanh()\n","  (gelu): GELU(approximate='none')\n","  (drop): Dropout(p=0.5, inplace=False)\n","  (classifier_decoder): Linear(in_features=768, out_features=30524, bias=True)\n","  (positional_embeddings): Embedding(32, 768)\n",")"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, BertConfig\n","\n","def apply_mask_to_encoder_hidden_state(encoder_hidden_state, attribute_tags, indices):\n","    # Apply the mask\n","    masked_tensor = torch.zeros_like(attribute_tags)\n","    for i, row in enumerate(attribute_tags):\n","        indices_to_mask = indices[i]\n","#         print(f\"row value: {row}\")\n","        masked_tensor[i, :indices_to_mask] = row[:indices_to_mask]\n","\n","    # Expand the dimensions of mask_tensor to match the shape of encoder_hidden_state\n","    expanded_mask = masked_tensor.unsqueeze(-1).expand_as(encoder_hidden_state)\n","\n","    # Apply the mask\n","    masked_encoder_hidden_state = encoder_hidden_state * expanded_mask\n","\n","    return masked_encoder_hidden_state\n","\n","\n","def find_indices_of_value(input_ids, value=102):\n","    indices_list = []\n","    for row in input_ids:\n","        indices = torch.where(row == value)[0]\n","        indices_list.append(indices.item() if len(indices) > 0 else None)\n","#     print(f\"Indices function: {indices_list}\")\n","    return indices_list\n","\n","\n","def create_query(input_ids,tags,target_ids):\n","    ## Size should be (4x128)\n","    # Mask for tensor_1 where parts with 0 are masked\n","    mask_tensor_1_zero = input_ids != 0\n","    # print(mask_tensor_1_zero)\n","    # Mask for tensor_2 where parts with values 3 and 4 are masked\n","    mask_tensor_2_3_4 = (tags == 3) | (tags == 4)\n","    double_mask = mask_tensor_1_zero & mask_tensor_2_3_4\n","\n","    # get the inputs_ids that satisfy both the condition\n","    result_tensor = double_mask.float() * input_ids\n","\n","    # Get indices of non-zero elements in each row\n","    nonzero_indices = torch.nonzero(result_tensor, as_tuple=False)\n","\n","    # Create a zero tensor of the same size as the original tensor\n","    query = torch.zeros_like(result_tensor)\n","\n","    # Fill the result tensor with the corresponding non-zero values from the original tensor\n","    row_prev,col_new=-500,0\n","    for idx in nonzero_indices:\n","        row, col = idx\n","#         print(row_prev)\n","        if row_prev==row:\n","            col_new=col_new+1\n","        else:\n","            col_new=0\n","            row_prev=row\n","        query[row, col_new] = result_tensor[row, col]\n","\n","    cols= target_ids.size()[1]\n","\n","    return query[:, :cols]\n","\n","\n","def generate_square_subsequent_mask(dim1: int, dim2: int , device = device):\n","\n","    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1).to(device)\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","\n","#     print(src_seq_len,tgt_seq_len)\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len,tgt_seq_len)\n","#     print(f\"tgt mask: {tgt_mask.size()}\")\n","    src_mask = generate_square_subsequent_mask(tgt_seq_len,src_seq_len)\n","#     print(f\"src mask: {src_mask.size()}\")\n","\n","    src_padding_mask = (src == 0).transpose(0, 1)\n","    tgt_padding_mask = (tgt == 0).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","\n","class BertSeq2SeqClassifier(nn.Module):\n","    def __init__(self,tokenizer, decoder_num_labels, freeze_bert=False, num_decoder_layers=4, decoder_max_len=16):\n","        super(BertSeq2SeqClassifier, self).__init__()\n","\n","        # BERT Encoder\n","        self.bert = BertModel.from_pretrained('bert-base-uncased', add_pooling_layer=False)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","        # # Hidden size from BERT\n","        hidden_size = self.bert.config.hidden_size\n","        self.bert_model = BertClassifier_1(tokenizer=tokenizer,freeze_bert=True)\n","        self.bert_model.to(device)\n","\n","        self.d_in, self.d_out_kq, self.d_out_v, self.num_heads = 769, 512, 128, 24\n","\n","        transformer_decoder_layer = nn.TransformerDecoderLayer(\n","            d_model=hidden_size,\n","            nhead=self.bert.config.num_attention_heads,\n","            dim_feedforward=self.bert.config.intermediate_size,\n","            activation=self.bert.config.hidden_act,\n","            layer_norm_eps=self.bert.config.layer_norm_eps,\n","            batch_first=True\n","        )\n","        self.transformer_decoder = nn.TransformerDecoder(\n","            transformer_decoder_layer,\n","            num_layers=num_decoder_layers\n","        )\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","        self.gelu = nn.GELU()\n","        self.drop = nn.Dropout(0.5)\n","\n","        # Classifier for decoder\n","        self.classifier_decoder = nn.Linear(hidden_size, decoder_num_labels)\n","\n","        # Positional Embeddings for Decoder\n","        self.positional_embeddings = nn.Embedding(decoder_max_len, hidden_size)\n","\n","\n","\n","    def generate(self,decoded_outputs):\n","        logits_decoder = self.classifier_decoder(decoded_outputs)\n","        return logits_decoder\n","\n","    def encode(self,input_ids, attention_mask,qty_pivot,labels):\n","        encoder_outputs,encoder_logits = self.bert_model(input_ids=input_ids, attention_mask=attention_mask,qty_pivot=qty_pivot,labels=labels)\n","        return encoder_outputs,encoder_logits\n","\n","\n","    def decode(self,input_ids,encoder_outputs,labels,encoder_logits,target_ids):\n","#         indices_list = find_indices_of_value(input_ids, value=102)\n","#         active_tags= encoder_logits.view(-1, 7)\n","#         flattened_tags = torch.argmax(active_tags, axis=1) # shape (batch_size * seq_len,)\n","#         attr_tags = torch.logical_or(flattened_tags==3,flattened_tags==4).view(-1,input_ids.size()[1]).type(torch.LongTensor).to(device).unsqueeze(2)\n","#         key_attribute = torch.cat((encoder_outputs.last_hidden_state,attr_tags),dim=2)\n","#         memory = self.relu(self.W(key_attribute))\n","\n","#         query = create_query(input_ids,labels,target_ids).type(torch.LongTensor).to(device)\n","        # print(f\"query train: {query}\")\n","        # print(f\"target train : {target_ids}\")\n","\n","        shifted_decoder_input_ids= torch.column_stack([30523 * torch.ones(len(target_ids)), target_ids.cpu()])[:, :-1].type(torch.LongTensor).to(device)\n","\n","#         positions = torch.arange(query.size(1), device=query.device).expand(query.size(0), -1)\n","        positions = torch.arange(shifted_decoder_input_ids.size(1), device=shifted_decoder_input_ids.device).expand(shifted_decoder_input_ids.size(0), -1)\n","\n","        pos_embeddings = self.positional_embeddings(positions)\n","\n","        decoder_inputs_embedded = self.bert.embeddings.word_embeddings(shifted_decoder_input_ids) + pos_embeddings\n","#         decoder_inputs_embedded = self.bert.embeddings.word_embeddings(query) + pos_embeddings\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(encoder_outputs.last_hidden_state, decoder_inputs_embedded)\n","\n","#         encoder_memory = apply_mask_to_encoder_hidden_state(encoder_outputs.last_hidden_state, flattened_tags.reshape(input_ids.size()), indices_list)\n","#         tag_centric_memory = torch.cat((encoder_memory,attr_tags),dim=2)\n","#         memory = self.relu(self.W(tag_centric_memory))\n","        memory = encoder_outputs.last_hidden_state\n","\n","\n","        decoded_outputs = self.transformer_decoder(tgt=decoder_inputs_embedded,\n","  #                                                    memory=encoder_outputs.last_hidden_state,\n","                                                    memory = memory,\n","                                                    tgt_mask= tgt_mask,\n","  #                                                    memory_mask=src_mask,\n","  #                                                    tgt_key_padding_mask=tgt_padding_mask,\n","                                                    # memory_key_padding_mask=src_boolean_mask,\n","                                                    tgt_is_causal=True)\n","        return decoded_outputs\n","\n","    def forward(self, input_ids, attention_mask, qty_pivot,labels,target_ids):\n","        encoder_outputs,encoder_logits = self.encode(input_ids=input_ids, attention_mask=attention_mask,qty_pivot=qty_pivot,labels=labels)\n","        decoded_outputs = self.decode(input_ids=input_ids,labels=labels,encoder_outputs=encoder_outputs,encoder_logits=encoder_logits,target_ids=target_ids)\n","\n","        return decoded_outputs,encoder_outputs,encoder_logits\n","\n","\n","# INITIATING SEQ2SEQ model\n","model = BertSeq2SeqClassifier(tokenizer=tokenizer,decoder_num_labels = 30524,num_decoder_layers=4,freeze_bert=True,decoder_max_len=32)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"VonVFYAjpdsS"},"source":["# Code Execution"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T07:18:12.720561Z","iopub.status.busy":"2024-05-08T07:18:12.720192Z","iopub.status.idle":"2024-05-08T11:42:01.653275Z","shell.execute_reply":"2024-05-08T11:42:01.652136Z","shell.execute_reply.started":"2024-05-08T07:18:12.720529Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import time\n","from datetime import timedelta\n","parameters = {\n","    \"MAX_LEN\":[128],\n","    \"MAX_GRAD_NORM\": [3,5],\n","    \"TRAIN_BATCH_SIZE\" : [8],\n","    \"LEARNING_RATE\": [1e-5]}\n","\n","\n","max_len_encoder,max_len_decoder,num_decoder_layers = 64,3,4\n","# import itertools\n","EPOCHS = 200\n","for comb in itertools.product(parameters[\"MAX_LEN\"],\n","                              parameters[\"MAX_GRAD_NORM\"],\n","                              parameters[\"TRAIN_BATCH_SIZE\"],\n","                              parameters[\"LEARNING_RATE\"]):\n","    print(\"Current Combination: \",comb)\n","\n","    MAX_LEN,MAX_GRAD_NORM,TRAIN_BATCH_SIZE,LEARNING_RATE = comb[0],comb[1],comb[2],comb[3]\n","\n","    # MAX_LEN, MAX_GRAD_NORM, TRAIN_BATCH_SIZE, LEARNING_RATE\n","\n","#     train_size = 0.95\n","#     train_dataset = df_.sample(frac=train_size,random_state=200)\n","#     test_dataset = df_.drop(train_dataset.index).reset_index(drop=True)\n","#     train_dataset = train_dataset.reset_index(drop=True)\n","    train_dataset = df_\n","    # print(\"FULL Dataset: {}\".format(df_.shape))\n","    # print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","    # print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","    training_set = EncoderDecoderDataset(train_dataset, tokenizer,max_len_encoder=max_len_encoder,max_len_decoder=max_len_decoder)\n","#     testing_set = EncoderDecoderDataset(test_dataset, tokenizer, 128,128)\n","\n","    train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                    'shuffle': True,\n","                    'num_workers': 4\n","                    }\n","    ######################## WE CAN DO GRID SEARCH CV HERE ##########3##########\n","    training_loader = DataLoader(training_set, **train_params)\n","#     testing_loader = DataLoader(testing_set, **test_params)\n","\n","    ###################### INITIALIZING THE MODEL FOR EACH SPLIT #####################################\n","    # model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n","    model = BertSeq2SeqClassifier(tokenizer=tokenizer,decoder_num_labels = 30524,num_decoder_layers=num_decoder_layers,freeze_bert=True,decoder_max_len=max_len_decoder)\n","    model.to(device)\n","    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","#     torch.cuda.empty_cache()\n","    f1_inference,alpha = 0.0, 0.50\n","    for epoch in range(EPOCHS):\n","        start_time = time.time()\n","        print(f\"Training epoch: {epoch + 1}\")\n","        train(training_loader,alpha=alpha,MAX_GRAD_NORM=MAX_GRAD_NORM)\n","        end_time = time.time()\n","        time_difference_seconds = end_time - start_time\n","        time_difference = timedelta(seconds=time_difference_seconds)\n","        # Extract minutes and seconds\n","        minutes = time_difference.seconds // 60\n","        seconds = time_difference.seconds % 60\n","        # Print time difference for the epoch\n","        print(f\"Epoch {epoch + 1}: Time taken - {minutes} minutes {seconds} seconds\")\n","\n","        pred_list,labels_list = inference_function_merge(df_test,max_len_encoder=max_len_encoder,max_len_decoder=max_len_decoder)\n","\n","        f1_current,preds = check_F1_score(ground_truth_attr,pred_list)\n","        # print(f\"Epoch value: {epoch}, current f1 score : {f1_current}\")\n","        # print(f\"Preds: {pred_list}\")\n","#         print(f\"Labels: {labels_list}\")\n","        if epoch>10 and f1_inference<f1_current:\n","            ### SAVE MODEL\n","            f1_inference=f1_current\n","            df = pd.DataFrame(zip(preds,ground_truth_attr,labels_list), columns=['preds','ground_truth','Tags'])\n","            df.to_csv(f\"/kaggle/working/f1={f1_current}-alpha={alpha}-non_tagcentric-deco{num_decoder_layers}--batchsize-{TRAIN_BATCH_SIZE}-epoch-{epoch}-maxlen-{max_len_decoder}.csv\",index=False)\n","            # print(f\"Epoch value: {epoch}, current f1 score : {f1_current} \\n\")\n","# print(\"\\n############### COMBINATION DONE #################\")\n","    print(\"\\n############### COMBINATION DONE #################\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Ea0MDy2ekA1i","vo4wGp5cm4Ln","kUMyWuCym4Lo"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4757128,"sourceId":8063850,"sourceType":"datasetVersion"},{"datasetId":4824294,"sourceId":8196122,"sourceType":"datasetVersion"},{"datasetId":4867243,"sourceId":8212598,"sourceType":"datasetVersion"},{"datasetId":4864525,"sourceId":8298176,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"088437bf51344b7aadaddbcec77b8277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d197ab664344458470220d26f2183b","placeholder":"​","style":"IPY_MODEL_5a79dfcad4434bc38e27daf925d920d5","value":"model.safetensors: 100%"}},"10f46cdb1f094dfaabf0c77bac8fbf38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1898071f6a764407979bf2d85566e9c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"208de58f057f47c785f9f0cdb9ca06e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d334f3291ba4fa592c28eb3b9095e7f","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_407489118d924fa49d98cfd4596b93ae","value":440449768}},"2546eedd8de44153b98cca98420ea7dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b28a4df322c445cbb24e312f7857bd10","IPY_MODEL_6ff9414071884dbba8bc1b2f8cb55961","IPY_MODEL_8a91eda0605c4431974f87ad9b4accd6"],"layout":"IPY_MODEL_e3d2263a1f5e47ad8b5aa8be7afa8962"}},"298a79fd205a43a984ce387030ac4c4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ab95d39f0974e8f9a3099b6c205e33f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c16ff464ae14c029c4b8d15e39f6b4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ced4137480b4975b6eca94b7e5942cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e75474880594d92a0b1b99644699bb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ed2c4ff57af4c33bed4dc4ba15180af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f99cd09e3644a29aadff38fb83bd323":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b7895ad6a4143e99bfa5656ce70f197":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f455c744b0d40b08820b7a014cca0d6","placeholder":"​","style":"IPY_MODEL_f2f4c6d997cb4bb884c9ef4ce4b222b0","value":"tokenizer.json: 100%"}},"3d94b0de433245efb0efe916cc99b2e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b7895ad6a4143e99bfa5656ce70f197","IPY_MODEL_70d32eeff70542aeaa8852bca89dc03c","IPY_MODEL_969bb478577b454da471721ac4842f95"],"layout":"IPY_MODEL_703dfae603e746e1819e5f114ce772b7"}},"3eb13f11069548b9b51c4f170d7a23ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"407489118d924fa49d98cfd4596b93ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48cfb7c25a0342968b7c51dd1d14e7c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e965406e1da41a5a0d0f1b0b6519cb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_298a79fd205a43a984ce387030ac4c4f","placeholder":"​","style":"IPY_MODEL_2e75474880594d92a0b1b99644699bb3","value":" 232k/232k [00:00&lt;00:00, 3.50MB/s]"}},"51a6931ae72b44afa71e77ae07eef6f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d197ab664344458470220d26f2183b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f9fc24e0d64491b7fa039fc7aaba5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_088437bf51344b7aadaddbcec77b8277","IPY_MODEL_208de58f057f47c785f9f0cdb9ca06e5","IPY_MODEL_ed35974842614bfc9eec6795f003b5b7"],"layout":"IPY_MODEL_629d6edd90e64690a5f6f17705ad9133"}},"57a55c057da247d68e9db6d97c9ae157":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65238eee1b9844f39961c64c755767c6","placeholder":"​","style":"IPY_MODEL_e0f93c3515da4d1f8ff1d9418815a0a0","value":"tokenizer_config.json: 100%"}},"5a79dfcad4434bc38e27daf925d920d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e734d58d4e542f98ddd63e50579efd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"629d6edd90e64690a5f6f17705ad9133":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65238eee1b9844f39961c64c755767c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6533149a227b4b989db044831011c9c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6719a85f57f14ffa9c0a006394f09b17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d677c28aaa4500a65fb033b303fb12","placeholder":"​","style":"IPY_MODEL_48cfb7c25a0342968b7c51dd1d14e7c1","value":" 48.0/48.0 [00:00&lt;00:00, 2.59kB/s]"}},"6ff9414071884dbba8bc1b2f8cb55961":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c16ff464ae14c029c4b8d15e39f6b4f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ed2c4ff57af4c33bed4dc4ba15180af","value":570}},"703dfae603e746e1819e5f114ce772b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70d32eeff70542aeaa8852bca89dc03c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb5a25c527604cf0964eeb61546b7304","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be629a950be34623a06c48d2ae4909de","value":466062}},"7f046a6ab33d42359c6c7799a7b5ac4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"833b5583b33f440aa27779ce30195ddf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_925dfdc0e25d4608b291c8159c03a8a3","IPY_MODEL_f5d110799157429790268b727255e735","IPY_MODEL_4e965406e1da41a5a0d0f1b0b6519cb6"],"layout":"IPY_MODEL_e8514f4a8a9b4c18bb18ab857bce13d8"}},"85d677c28aaa4500a65fb033b303fb12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a91eda0605c4431974f87ad9b4accd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de4e6176b59e4709a9b270a7369cd101","placeholder":"​","style":"IPY_MODEL_7f046a6ab33d42359c6c7799a7b5ac4f","value":" 570/570 [00:00&lt;00:00, 45.7kB/s]"}},"8ccfb776d3d94d089a0687d5ca5d2e85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57a55c057da247d68e9db6d97c9ae157","IPY_MODEL_b59440f3cec941948fd218eafd64e72e","IPY_MODEL_6719a85f57f14ffa9c0a006394f09b17"],"layout":"IPY_MODEL_b9d8372c69e545f39b9836fea0f2c8b3"}},"8f455c744b0d40b08820b7a014cca0d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925dfdc0e25d4608b291c8159c03a8a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6533149a227b4b989db044831011c9c9","placeholder":"​","style":"IPY_MODEL_2ced4137480b4975b6eca94b7e5942cf","value":"vocab.txt: 100%"}},"969bb478577b454da471721ac4842f95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e736364f329a42cba503eb778dfe3e3d","placeholder":"​","style":"IPY_MODEL_10f46cdb1f094dfaabf0c77bac8fbf38","value":" 466k/466k [00:00&lt;00:00, 2.35MB/s]"}},"9bb8242ab34243c98d9bf2fbf75d5401":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d334f3291ba4fa592c28eb3b9095e7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b28a4df322c445cbb24e312f7857bd10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f99cd09e3644a29aadff38fb83bd323","placeholder":"​","style":"IPY_MODEL_5e734d58d4e542f98ddd63e50579efd8","value":"config.json: 100%"}},"b59440f3cec941948fd218eafd64e72e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51a6931ae72b44afa71e77ae07eef6f0","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1898071f6a764407979bf2d85566e9c2","value":48}},"b9d8372c69e545f39b9836fea0f2c8b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be629a950be34623a06c48d2ae4909de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dca00133749140a9b3fabe0ff34e97ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de4e6176b59e4709a9b270a7369cd101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f93c3515da4d1f8ff1d9418815a0a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3d2263a1f5e47ad8b5aa8be7afa8962":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e736364f329a42cba503eb778dfe3e3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8514f4a8a9b4c18bb18ab857bce13d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5a25c527604cf0964eeb61546b7304":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed35974842614bfc9eec6795f003b5b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab95d39f0974e8f9a3099b6c205e33f","placeholder":"​","style":"IPY_MODEL_3eb13f11069548b9b51c4f170d7a23ba","value":" 440M/440M [00:01&lt;00:00, 208MB/s]"}},"f2f4c6d997cb4bb884c9ef4ce4b222b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5d110799157429790268b727255e735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb8242ab34243c98d9bf2fbf75d5401","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dca00133749140a9b3fabe0ff34e97ec","value":231508}}}}},"nbformat":4,"nbformat_minor":4}
